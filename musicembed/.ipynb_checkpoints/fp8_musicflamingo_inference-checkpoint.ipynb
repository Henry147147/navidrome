{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d472db43",
   "metadata": {},
   "source": [
    "# MusicFlamingo FP8 LLM + Multimodal Inference\n",
    "\n",
    "This notebook loads the full **MusicFlamingoForConditionalGeneration** model while swapping in the **FP8‑quantized LLM** from `models/music-flamingo-2601-llm-fp8`.\n",
    "It then runs a single audio + text inference to verify the multimodal path works.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8727bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "from safetensors import safe_open\n",
    "from huggingface_hub import hf_hub_download\n",
    "from transformers import (\n",
    "    MusicFlamingoConfig,\n",
    "    MusicFlamingoForConditionalGeneration,\n",
    "    AutoProcessor,\n",
    "    AutoModelForCausalLM,\n",
    ")\n",
    "import shutil\n",
    "\n",
    "\n",
    "model_id = \"nvidia/music-flamingo-2601-hf\"\n",
    "llm_dir = \"models/music-flamingo-2601-llm-fp8\"\n",
    "full_model_path = \"models/full-music-flamingo.safetensor\"\n",
    "mmproj_model = \"models/mmproj-music-flamingo.safetensor\"\n",
    "\n",
    "\n",
    "if not Path(llm_dir).exists():\n",
    "    raise FileNotFoundError(f\"Missing FP8 LLM dir: {llm_dir}\")\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError(\"CUDA is required for FP8 inference.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b6bae6-c499-4b4d-b706-5aaa22401a68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8eb9ae56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading base config...\n",
      "Loading audio_tower + multi_modal_projector weights...\n",
      "Loaded 492 tensors for audio + projector\n",
      "Loading FP8 LLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6b248fbbbe04d939bff958094d52b2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/535 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving audio_tower and projector to GPU (bf16)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading processor...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading base config...\")\n",
    "config = MusicFlamingoConfig.from_pretrained(model_id)\n",
    "model = MusicFlamingoForConditionalGeneration(config)\n",
    "model.eval()\n",
    "\n",
    "print(\"Loading audio_tower + multi_modal_projector weights...\")\n",
    "weights_path = hf_hub_download(model_id, filename=\"model.safetensors\")\n",
    "#shutil.move(source\n",
    "state_dict = {}\n",
    "with safe_open(weights_path, framework=\"pt\", device=\"cpu\") as f:\n",
    "    for k in f.keys():\n",
    "        if k.startswith(\"audio_tower.\") or k.startswith(\"multi_modal_projector.\"):\n",
    "            state_dict[k] = f.get_tensor(k)\n",
    "missing, unexpected = model.load_state_dict(state_dict, strict=False)\n",
    "print(f\"Loaded {len(state_dict)} tensors for audio + projector\")\n",
    "\n",
    "print(\"Loading FP8 LLM...\")\n",
    "llm = AutoModelForCausalLM.from_pretrained(\n",
    "    llm_dir,\n",
    "    device_map=\"cuda\",\n",
    "    dtype=\"auto\",\n",
    ")\n",
    "model.language_model = llm\n",
    "model.vocab_size = llm.config.vocab_size\n",
    "model.config.text_config = llm.config\n",
    "\n",
    "print(\"Moving audio_tower and projector to GPU (bf16)...\")\n",
    "model.audio_tower = model.audio_tower.to(device=\"cuda\", dtype=torch.bfloat16)\n",
    "model.multi_modal_projector = model.multi_modal_projector.to(device=\"cuda\", dtype=torch.bfloat16)\n",
    "\n",
    "print(\"Loading processor...\")\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f630425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Output ===\n",
      "\n",
      "This track is an energetic Eurodance / Dance‑Pop anthem that blends the bright, hook‑laden sensibility of mainstream pop with the driving, club‑ready pulse of classic Eurodance.  The duration of the piece is 163.59 seconds.\n",
      "Tempo & key – The song moves at a brisk 150 BPM and is rooted in E major.\n",
      "Instrumentation & production – A polished, high‑fidelity production frames the arrangement. The rhythm foundation is built on a four‑on‑the‑floor electronic drum kit with crisp kick,\n"
     ]
    }
   ],
   "source": [
    "conversation = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": (\n",
    "                    \"Describe this track in full detail - tell me the genre, tempo, and key, then \"\n",
    "                    \"dive into the instruments, production style, and overall mood it creates.\"\n",
    "                ),\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"audio\",\n",
    "                \"path\": \"https://huggingface.co/datasets/nvidia/AudioSkills/resolve/main/assets/song_1.mp3\",\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "inputs = processor.apply_chat_template(\n",
    "    conversation,\n",
    "    tokenize=True,\n",
    "    add_generation_prompt=True,\n",
    "    return_dict=True,\n",
    ")\n",
    "\n",
    "# Move all inputs to GPU (audio + text)\n",
    "for key, value in list(inputs.items()):\n",
    "    if torch.is_tensor(value):\n",
    "        inputs[key] = value.to(\"cuda\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(**inputs, max_new_tokens=128)\n",
    "\n",
    "decoded = processor.batch_decode(\n",
    "    outputs[:, inputs[\"input_ids\"].shape[1]:],\n",
    "    skip_special_tokens=True,\n",
    ")\n",
    "print(\"\\n=== Output ===\\n\")\n",
    "print(decoded[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3397d476-e231-48f4-8168-ff47ad26e4fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "navidrome",
   "language": "python",
   "name": "nav_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
